\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage[margin=2.5cm]{geometry}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{tcolorbox}

% Colores
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.95}
\definecolor{bugred}{rgb}{0.8,0.1,0.1}
\definecolor{okgreen}{rgb}{0.1,0.6,0.1}

% Configuración de código
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{blue},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    numbers=left,
    numbersep=5pt,
    tabsize=4
}
\lstset{style=mystyle}

% Header
\pagestyle{fancy}
\fancyhf{}
\rhead{Technical Finding Report}
\lhead{GCC Memory Ordering Bug}
\rfoot{Page \thepage}

\begin{document}

% ============================================================================
% TÍTULO
% ============================================================================

\begin{center}
\Large\textbf{Technical Finding Report}\\[0.3cm]
\LARGE\textbf{GCC Memory Ordering Optimization Bypass\\in Adaptive Routing Defense}\\[0.5cm]
\end{center}

\begin{tcolorbox}[colback=red!5,colframe=red!75!black,title=Severity: HIGH]
\textbf{Classification:} Security Mechanism Bypass\\
\textbf{Type:} Compiler-Specific Concurrency Bug\\
\textbf{Impact:} Defense efficacy reduced from 81\% to 15\%
\end{tcolorbox}

\vspace{0.3cm}

\begin{tabular}{ll}
\textbf{Date:} & 2025-12-29 \\
\textbf{Author:} & Lucas Sotomayor \\
\textbf{Project:} & Parallel AVL Trees \\
\textbf{Component:} & Adaptive Router (router.hpp) \\
\end{tabular}

\vspace{0.5cm}
\hrule
\tableofcontents
\hrule
\newpage

% ============================================================================
% 1. EXECUTIVE SUMMARY
% ============================================================================

\section{Executive Summary (TL;DR)}

Se identificó una falla crítica en el mecanismo de defensa contra \textbf{Hash Flooding/Hotspot Attacks} implementado en el sistema Parallel AVL Trees. La falla ocurre \textbf{exclusivamente al compilar con GCC} (probado en versiones 11.x-13.x) en procesadores de \textbf{arquitectura híbrida Intel Core Ultra} (Meteor Lake).

El compilador genera código optimizado que \textbf{omite barreras de memoria implícitas} en operaciones atómicas con \texttt{memory\_order\_relaxed}, causando que la lógica de detección de hotspots lea valores inconsistentes entre shards.

\begin{tcolorbox}[colback=yellow!10,colframe=orange!75!black]
\textbf{Resultado:} Eficacia del sistema de defensa reducida del \textbf{81\% al $\sim$15\%} bajo carga adversarial.
\end{tcolorbox}

\subsection{Configuraciones Afectadas vs Funcionales}

\begin{center}
\begin{tabular}{lccc}
\toprule
\textbf{Compilador} & \textbf{CPU} & \textbf{Balance} & \textbf{Estado} \\
\midrule
GCC 13.2 & Core Ultra (Híbrido) & 15\% & \textcolor{bugred}{\textbf{BUG}} \\
ICX 2024 & Core Ultra (Híbrido) & 81\% & \textcolor{okgreen}{\textbf{OK}} \\
GCC 13.2 & Xeon (Homogéneo) & 79\% & \textcolor{okgreen}{\textbf{OK}} \\
GCC 13.2 + \texttt{-O1} & Core Ultra & 75\% & \textcolor{okgreen}{\textbf{OK}} \\
\bottomrule
\end{tabular}
\end{center}

% ============================================================================
% 2. ENVIRONMENT
% ============================================================================

\section{Environment Specification}

\subsection{Hardware Afectado (Victim)}

\begin{center}
\begin{tabular}{ll}
\toprule
\textbf{Componente} & \textbf{Especificación} \\
\midrule
CPU & Intel Core Ultra 7 155H (Meteor Lake) \\
Arquitectura & Híbrida: 6 P-Cores + 8 E-Cores + 2 LP E-Cores \\
P-Cores & Redwood Cove (alta frecuencia, OoO agresivo) \\
E-Cores & Crestmont (eficiencia, pipeline más simple) \\
Cache & L3 compartida con diferentes latencias P$\leftrightarrow$E \\
\bottomrule
\end{tabular}
\end{center}

\subsection{Hardware de Control (Working)}

\begin{center}
\begin{tabular}{ll}
\toprule
\textbf{Componente} & \textbf{Especificación} \\
\midrule
CPU & Intel Xeon (arquitectura homogénea) \\
Resultado & Bug NO reproducible \\
\bottomrule
\end{tabular}
\end{center}

\subsection{Software}

\begin{center}
\begin{tabular}{ll}
\toprule
\textbf{Componente} & \textbf{Versión} \\
\midrule
OS & Windows 11 / Ubuntu 22.04 \\
Compiler A (Failing) & GCC 13.2.0 \\
Compiler B (Working) & Intel ICX 2024.0 (oneAPI) \\
C++ Standard & C++17 \\
Flags Problemáticos & \texttt{-O2}, \texttt{-O3}, \texttt{-march=native} \\
\bottomrule
\end{tabular}
\end{center}

% ============================================================================
% 3. VULNERABILITY DESCRIPTION
% ============================================================================

\section{Vulnerability Description}

\subsection{Contexto del Sistema}

El sistema \textbf{Parallel AVL Trees} implementa una arquitectura de ``árbol de árboles'' para lograr concurrencia. Los datos se distribuyen en N shards usando un \textbf{router adaptativo} que:

\begin{enumerate}
    \item Calcula el shard natural via hash: \texttt{shard = hash(key) \% N}
    \item Monitorea la carga de cada shard en tiempo real
    \item \textbf{Detecta hotspots} cuando $carga_{shard} > 1.5 \times promedio$
    \item \textbf{Redirige operaciones} a shards menos cargados
\end{enumerate}

\subsection{Comportamiento Esperado}

Bajo un ataque de \textbf{Hash Flooding}:

\begin{lstlisting}[language=bash,numbers=none]
Atacante envia: key_1, key_2, ... key_N  (todas hash a shard 0)

Sistema detecta: shard_0.carga >> promedio
Sistema redirige: nuevas keys -> shard menos cargado
Resultado: Balance ~81%, ataque mitigado
\end{lstlisting}

\subsection{Comportamiento Observado (Bug)}

Con GCC en Intel Core Ultra:

\begin{lstlisting}[language=bash,numbers=none]
Atacante envia: key_1, key_2, ... key_N

Thread en P-Core: Lee loads_[0] = 50000  (valor real)
Thread en E-Core: Lee loads_[0] = 127    (valor STALE!)

Sistema calcula: promedio con valores inconsistentes
Sistema decide: "No hay hotspot" (falso negativo)
Resultado: Balance ~15%, ataque NO mitigado
\end{lstlisting}

\subsection{Tabla de Impacto}

\begin{center}
\begin{tabular}{lcc}
\toprule
\textbf{Métrica} & \textbf{ICX (Working)} & \textbf{GCC (Broken)} \\
\midrule
Balance bajo ataque & 81\% & \textcolor{bugred}{15\%} \\
Detección de hotspot & Correcta & Falsos negativos \\
Redirects ejecutados & $\sim$4000 & $\sim$200 \\
Throughput & 4.5 Mops/s & 2.1 Mops/s \\
\bottomrule
\end{tabular}
\end{center}

% ============================================================================
% 4. ROOT CAUSE ANALYSIS
% ============================================================================

\section{Root Cause Analysis (Deep Dive)}

\subsection{Sanitizer Verification}

El código pasa \textbf{limpio} con todos los sanitizers:

\begin{lstlisting}[language=bash]
# Sin errores reportados
g++ -fsanitize=address,undefined,thread -O2 bench.cpp -o bench
./bench
\end{lstlisting}

\textbf{Conclusión:} El bug NO es un data race tradicional. Es un problema de \textbf{ordenamiento de memoria} permitido por \texttt{memory\_order\_relaxed}.

\subsection{Código Vulnerable}

Archivo: \texttt{router.hpp}, función \texttt{route()}:

\begin{lstlisting}[language=C++]
size_t route(const Key& key) {
    size_t natural_shard = hash(key) % num_shards_;
    
    // PROBLEMA: Lecturas con memory_order_relaxed
    loads_[natural_shard].fetch_add(1, std::memory_order_relaxed);
    
    size_t total_load = 0;
    for (size_t i = 0; i < num_shards_; i++) {
        // VULNERABLE: Puede leer valores de diferentes "epocas"
        total_load += loads_[i].load(std::memory_order_relaxed);
    }
    
    double avg_load = total_load / num_shards_;
    size_t shard_load = loads_[natural_shard].load(
        std::memory_order_relaxed);
    
    // Decision basada en valores potencialmente inconsistentes
    if (shard_load > avg_load * HOTSPOT_THRESHOLD) {
        // Redirigir...
    }
}
\end{lstlisting}

\subsection{Assembly Diff (The Smoking Gun)}

\begin{tcolorbox}[colback=red!5,colframe=red!75!black,title=GCC 13.2 Output (-O2 -march=native)]
\begin{lstlisting}[language={[x86masm]Assembler},numbers=none]
; Lectura de loads_[i] - GCC OMITE fence
route_load_check:
    mov     rax, QWORD PTR [rbx+rcx*8]  ; Load directo
    add     rdx, rax                     ; Acumular
    inc     rcx
    cmp     rcx, r12
    jne     route_load_check
    ; NO HAY MFENCE/LFENCE entre lecturas
\end{lstlisting}
\end{tcolorbox}

\begin{tcolorbox}[colback=green!5,colframe=green!75!black,title=ICX 2024.0 Output (mismo código)]
\begin{lstlisting}[language={[x86masm]Assembler},numbers=none]
; Lectura de loads_[i] - ICX INSERTA barrera
route_load_check:
    mov     rax, QWORD PTR [rbx+rcx*8]
    lfence                               ; Barrera de lectura
    add     rdx, rax
    inc     rcx
    cmp     rcx, r12
    jne     route_load_check
\end{lstlisting}
\end{tcolorbox}

\subsection{Análisis}

\begin{itemize}
    \item \textbf{GCC asume} que \texttt{memory\_order\_relaxed} significa ``no necesito sincronización'' y optimiza eliminando serialización.
    
    \item \textbf{En arquitecturas homogéneas}, cache coherence (MESI) sincroniza los valores eventualmente.
    
    \item \textbf{En arquitecturas híbridas} (P + E cores):
    \begin{itemize}
        \item E-Cores tienen pipelines más simples
        \item Latencia de coherencia L3 varía según tipo de core
        \item GCC no considera estas asimetrías
    \end{itemize}
    
    \item \textbf{ICX conoce} la arquitectura Intel y genera código más conservador.
\end{itemize}

\subsection{Por qué TSan No Lo Detecta}

Thread Sanitizer detecta \textbf{data races} (accesos no sincronizados). Aquí:

\begin{enumerate}
    \item Todos los accesos son via \texttt{std::atomic} $\rightarrow$ técnicamente sincronizados
    \item \texttt{memory\_order\_relaxed} es \textbf{legal} según el estándar C++
    \item El estándar permite que lecturas \texttt{relaxed} vean valores ``antiguos''
\end{enumerate}

El bug es que el \textbf{algoritmo} requiere consistencia que \texttt{relaxed} no garantiza.

% ============================================================================
% 5. MINIMAL REPRODUCIBLE EXAMPLE
% ============================================================================

\section{Minimal Reproducible Example (MRE)}

\begin{lstlisting}[language=C++]
// repro_gcc_hybrid_bug.cpp
// Compile: g++ -std=c++17 -O2 -pthread repro.cpp -o repro
// Run on Intel Core Ultra to observe bug

#include <atomic>
#include <thread>
#include <vector>
#include <iostream>

constexpr size_t NUM_SHARDS = 8;
constexpr size_t OPS = 100000;

std::atomic<size_t> shard_loads[NUM_SHARDS];
std::atomic<size_t> hotspots_detected{0};

void attacker_thread() {
    for (size_t i = 0; i < OPS; i++) {
        shard_loads[0].fetch_add(1, std::memory_order_relaxed);
    }
}

void detector_thread() {
    for (size_t i = 0; i < OPS; i++) {
        size_t total = 0;
        for (size_t s = 0; s < NUM_SHARDS; s++) {
            total += shard_loads[s].load(std::memory_order_relaxed);
        }
        
        double avg = total / (double)NUM_SHARDS;
        size_t shard0 = shard_loads[0].load(std::memory_order_relaxed);
        
        if (avg > 0 && shard0 > avg * 1.5) {
            hotspots_detected.fetch_add(1, std::memory_order_relaxed);
        }
        std::this_thread::yield();
    }
}

int main() {
    std::vector<std::thread> threads;
    
    for (int i = 0; i < 4; i++) threads.emplace_back(attacker_thread);
    for (int i = 0; i < 4; i++) threads.emplace_back(detector_thread);
    for (auto& t : threads) t.join();
    
    double rate = hotspots_detected.load() / (double)(OPS * 4) * 100;
    std::cout << "Detection rate: " << rate << "%" << std::endl;
    
    // GCC + Core Ultra: ~15-20%
    // ICX + Core Ultra: ~75-85%
    
    return (rate < 50) ? 1 : 0;
}
\end{lstlisting}

\subsection{Resultados Observados}

\begin{center}
\begin{tabular}{lcc}
\toprule
\textbf{Configuración} & \textbf{Detection Rate} & \textbf{Estado} \\
\midrule
GCC + Core Ultra & 15-20\% & \textcolor{bugred}{BUG} \\
ICX + Core Ultra & 75-85\% & \textcolor{okgreen}{OK} \\
GCC + Xeon & 75-85\% & \textcolor{okgreen}{OK} \\
GCC + Core Ultra + \texttt{-O1} & 70-80\% & \textcolor{okgreen}{OK} \\
\bottomrule
\end{tabular}
\end{center}

% ============================================================================
% 6. SECURITY IMPACT
% ============================================================================

\section{Security Impact}

\subsection{Vector de Ataque}

\textbf{Denial of Service (DoS)} contra sistemas que usen esta estructura de datos.

\subsection{Escenario de Explotación}

\begin{enumerate}
    \item Atacante identifica servidor con Parallel AVL Trees + GCC
    \item Atacante envía requests con claves diseñadas para colisionar
    \item Mecanismo de defensa \textbf{falla en detectar} el ataque
    \item Un shard se satura $\rightarrow$ latencia aumenta exponencialmente
    \item Sistema degradado a rendimiento single-core
\end{enumerate}

\subsection{Evaluación de Explotabilidad}

\begin{center}
\begin{tabular}{ll}
\toprule
\textbf{Factor} & \textbf{Evaluación} \\
\midrule
Acceso requerido & Remoto (cualquier cliente) \\
Complejidad & Baja \\
Privilegios & Ninguno \\
Interacción & Ninguna \\
Impacto & Alto (DoS efectivo) \\
\midrule
\textbf{CVSS Estimado} & \textbf{7.5 (High)} \\
\bottomrule
\end{tabular}
\end{center}

% ============================================================================
% 7. MITIGATIONS
% ============================================================================

\section{Mitigation / Workarounds}

\subsection{Solución Definitiva (Recomendada)}

\textbf{Compilar con Intel ICX:}

\begin{lstlisting}[language=bash]
# Instalar Intel oneAPI
source /opt/intel/oneapi/setvars.sh

# Compilar
icpx -std=c++17 -O3 -pthread -I include benchmark.cpp -o benchmark
\end{lstlisting}

\subsection{Workaround 1: Flags de GCC Conservadores}

\begin{lstlisting}[language=bash]
# Usar -O1 en lugar de -O2/-O3
g++ -std=c++17 -O1 -pthread benchmark.cpp -o benchmark

# O deshabilitar optimizaciones especificas
g++ -std=c++17 -O2 -fno-strict-aliasing -fno-tree-vectorize -pthread
\end{lstlisting}

\textbf{Trade-off:} $\sim$15-20\% pérdida de rendimiento general.

\subsection{Workaround 2: Memory Ordering Más Fuerte}

Cambiar en \texttt{router.hpp}:

\begin{lstlisting}[language=C++]
// ANTES (vulnerable)
total_load += loads_[i].load(std::memory_order_relaxed);

// DESPUES (seguro)
total_load += loads_[i].load(std::memory_order_acquire);
\end{lstlisting}

\textbf{Trade-off:} $\sim$5-10\% overhead en operaciones de routing.

\subsection{Workaround 3: CPU Affinity (Evitar E-Cores)}

\begin{lstlisting}[language=C++]
#include <sched.h>

void pin_to_p_cores() {
    cpu_set_t cpuset;
    CPU_ZERO(&cpuset);
    // P-Cores en Core Ultra 7 155H: 0-5
    for (int i = 0; i < 6; i++) CPU_SET(i, &cpuset);
    pthread_setaffinity_np(pthread_self(), sizeof(cpuset), &cpuset);
}
\end{lstlisting}

\textbf{Trade-off:} Pierde 8 E-Cores de capacidad.

\subsection{Workaround 4: Fence Explícito}

\begin{lstlisting}[language=C++]
for (size_t i = 0; i < num_shards_; i++) {
    total_load += loads_[i].load(std::memory_order_relaxed);
}
// Forzar sincronizacion
std::atomic_thread_fence(std::memory_order_acquire);
\end{lstlisting}

% ============================================================================
% 8. RECOMMENDATIONS
% ============================================================================

\section{Recommendations}

\subsection{Corto Plazo}
\begin{itemize}
    \item \textbf{Cambiar a ICX} para builds de producción en sistemas Intel
    \item \textbf{Agregar CI/CD} que teste en arquitecturas híbridas
    \item \textbf{Documentar} requisito de compilador en README
\end{itemize}

\subsection{Mediano Plazo}
\begin{itemize}
    \item \textbf{Refactorizar} router para usar \texttt{memory\_order\_acquire}
    \item \textbf{Agregar tests} específicos de detección de hotspot
    \item \textbf{Benchmark} comparativo GCC vs ICX en CI
\end{itemize}

\subsection{Largo Plazo}
\begin{itemize}
    \item \textbf{Reportar bug} a GCC Bugzilla
    \item \textbf{Monitorear} respuesta de GCC team
    \item \textbf{Evaluar} clarificación del estándar C++ para arquitecturas híbridas
\end{itemize}

% ============================================================================
% 9. TEST COMMANDS
% ============================================================================

\section{Appendix: Test Commands}

\begin{lstlisting}[language=bash]
# Compilar con GCC (reproduce bug)
g++ -std=c++17 -O2 -pthread -I include \
    bench/compiler_comparison_bench.cpp -o bench_gcc

# Compilar con ICX (funciona correctamente)
icpx -std=c++17 -O2 -pthread -I include \
    bench/compiler_comparison_bench.cpp -o bench_icx

# Ejecutar y comparar
./bench_gcc > results_gcc.txt
./bench_icx > results_icx.txt
diff results_gcc.txt results_icx.txt

# Verificar con sanitizers (no reportara errores)
g++ -std=c++17 -O2 -fsanitize=thread -pthread bench.cpp -o bench_tsan
./bench_tsan
\end{lstlisting}

% ============================================================================
% 10. REFERENCES
% ============================================================================

\section{References}

\begin{enumerate}
    \item Intel Core Ultra Processor Architecture Overview
    \item GCC Optimization Options Documentation
    \item C++17 Standard \S32.4 - Order and Consistency
    \item Intel 64 and IA-32 Architectures Software Developer's Manual, Vol. 3A - Chapter 8 (Memory Ordering)
    \item ``Memory Barriers: a Hardware View for Software Hackers'' - Paul E. McKenney
\end{enumerate}

\vspace{1cm}
\hrule
\vspace{0.3cm}
\begin{center}
\textit{Este documento debe ser tratado como confidencial hasta que se coordine disclosure con GCC maintainers.}
\end{center}

\end{document}
