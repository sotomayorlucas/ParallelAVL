# Reporte de Trabajos Futuros - Parallel AVL Tree

**Fecha**: 29 de Diciembre, 2025  
**Autor**: Lucas Sotomayor  
**Proyecto**: √Årboles AVL Paralelos con Arquitectura Sharded

---

## Resumen Ejecutivo

Este documento presenta los resultados de la implementaci√≥n y evaluaci√≥n de cuatro l√≠neas de trabajo futuro propuestas para el proyecto de √Årboles AVL Paralelos:

1. **Read-Copy-Update (RCU) / shared_mutex** - ‚ùå No recomendado
2. **Routing Predictivo ML-lite** - ‚ö†Ô∏è Redundante con hash robusto
3. **Shards Din√°micos** - ‚úÖ **Exitoso y recomendado**
4. **Extensi√≥n Distribuida** - üìã Framework dise√±ado, pendiente implementaci√≥n

---

## 1. shared_mutex para Lecturas Concurrentes

### Hip√≥tesis
> "Reemplazar `std::mutex` por `std::shared_mutex` permitir√° lecturas paralelas, mejorando el rendimiento en cargas read-heavy."

### Resultados

| Implementaci√≥n | Tiempo (600K ops) | Throughput |
|----------------|-------------------|------------|
| V1 (std::mutex) | 31.68 ms | **18.9M ops/s** |
| V2 (std::shared_mutex) | 1086.24 ms | 552K ops/s |

**Resultado: 34√ó m√°s lento con shared_mutex**

### An√°lisis

El modelo mental "m√°s readers en paralelo = mejor" asume que el costo de la operaci√≥n protegida domina. En nuestro caso:

```
Tiempo total = T_lock + T_operaci√≥n + T_unlock

std::mutex:        ~50ns + ~300ns + ~10ns  = ~360ns
std::shared_mutex: ~400ns + ~300ns + ~150ns = ~850ns
```

El overhead de `shared_mutex` (coordinaci√≥n de reader count at√≥mico) **excede el costo de la operaci√≥n AVL**.

### Lecci√≥n Aprendida
`shared_mutex` solo conviene cuando:
- Operaciones protegidas son costosas (>10Œºs): I/O, red, c√°lculos complejos
- Ratio de lecturas >99% con muy pocos writers

### Recomendaci√≥n
**No implementar** para operaciones en memoria pura. Mantener `std::mutex` simple.

---

## 2. Routing Predictivo (ML-lite)

### Hip√≥tesis
> "Un predictor basado en EMA (Exponential Moving Average) puede detectar hotspots antes de que ocurran y redistribuir proactivamente."

### Resultados

| Estrategia | Throughput | Balance | Hotspots Detectados |
|------------|------------|---------|---------------------|
| Static Hash | 3.4M ops/s | 99.5% | N/A |
| Predictive (EMA) | 2.4M ops/s | 99.5% | 0 |

**Resultado: 29% m√°s lento, sin beneficio**

### An√°lisis

El predictor no detect√≥ hotspots porque nuestro hash robusto (Murmur3 finalizer) distribuye **demasiado bien**:

```cpp
h ^= h >> 33;
h *= 0xff51afd7ed558ccdULL;  // Efecto avalancha
h ^= h >> 33;
```

Incluso con distribuci√≥n Zipf (sesgada), el hash la "uniformiza".

### Lecci√≥n Aprendida
El routing predictivo es √∫til **solo si**:
- El hash permite hotspots (hash d√©bil o identity hash)
- Hay ataques adversariales reales
- El patr√≥n de acceso es predecible temporalmente

### Recomendaci√≥n
**No implementar**. El router adversary-resistant existente (`router.hpp`) ya maneja estos casos de forma m√°s eficiente.

---

## 3. Shards Din√°micos con Consistent Hashing ‚úÖ

### Hip√≥tesis
> "Usando consistent hashing y migraci√≥n activa, se puede escalar horizontalmente sin perder balance."

### Resultados

| Fase | AVLTreeParallelV2 (sin migraci√≥n) | DynamicShardedTree (con migraci√≥n) |
|------|-----------------------------------|-----------------------------------|
| 4 shards | 84.6% balance | 82.9% balance |
| 6 shards | 62.5% balance | 89.1% balance |
| 8 shards | **52.2% balance** ‚ö†Ô∏è | **87.7% balance** ‚úì |

**Throughput comparativo:**
- AVLTreeParallelV2: 735K ops/s
- DynamicShardedTree: **1.05M ops/s** (+43%)

**Velocidad de rebalance:** 3.5M keys/sec

### An√°lisis

El problema con el enfoque anterior era que al agregar shards:
```
hash(key) % 4 = 2  ‚Üí  Shard 2
hash(key) % 6 = 4  ‚Üí  Shard 4  (¬°pero el dato est√° en Shard 2!)
```

Sin migraci√≥n, los datos viejos quedan desbalanceados.

**Soluci√≥n implementada:**
1. **Consistent Hash Ring** con 64 virtual nodes por shard
2. **Migraci√≥n Lazy** durante operaciones `contains()`/`get()`
3. **`force_rebalance()`** para redistribuci√≥n completa cuando sea necesario

### Implementaci√≥n

```cpp
// include/DynamicShardedTree.hpp
template<typename Key, typename Value = Key>
class DynamicShardedTree {
    // Consistent hash ring
    std::vector<VirtualNode> hash_ring_;
    
    // Scaling din√°mico
    void add_shard();
    void remove_shard();
    void force_rebalance();
    
    // Migraci√≥n lazy integrada en contains()/get()
};
```

### Recomendaci√≥n
**Implementar y usar** como reemplazo de AVLTreeParallel para casos que requieran escalado el√°stico.

---

## 4. Extensi√≥n Distribuida

### Estado
Framework dise√±ado, implementaci√≥n parcial como stub.

### Componentes Dise√±ados

```
         [Client Layer]
               |
        [Router/Coordinator]
               |
   +------+----+----+------+
   |      |         |      |
[Node 0] [Node 1] [Node 2] [Node 3]
Shards   Shards   Shards   Shards
0-7      8-15     16-23    24-31
```

- `DistributedCoordinator`: Routing entre nodos, health tracking
- `DistributedAVLNode`: Wrapper del √°rbol local con operaciones remotas
- `ClusterManager`: Helper para crear clusters de testing
- Soporte para consistencia STRONG/EVENTUAL/CAUSAL

### Lo que Falta
1. **Transport real**: gRPC, TCP sockets, o similar
2. **Consensus protocol**: Raft/Paxos para consistencia fuerte
3. **Failure handling**: Detecci√≥n de particiones, recuperaci√≥n
4. **Replicaci√≥n**: Implementaci√≥n completa de sync/async

### Recomendaci√≥n
**Posponer** hasta que haya un caso de uso real que justifique la complejidad.

---

## Plan de Integraci√≥n: DynamicShardedTree

### Fase 1: Preparaci√≥n (D√≠a 1)

#### 1.1 Verificar compatibilidad de API

```cpp
// API actual (AVLTreeParallel)
tree.insert(key, value);
tree.contains(key);
tree.get(key);
tree.remove(key);
tree.size();

// API nueva (DynamicShardedTree) - COMPATIBLE ‚úì
tree.insert(key, value);
tree.contains(key);
tree.get(key);
tree.remove(key);
tree.size();

// M√©todos adicionales
tree.add_shard();           // Nuevo: escalar horizontalmente
tree.remove_shard();        // Nuevo: reducir shards
tree.force_rebalance();     // Nuevo: redistribuir datos
tree.get_stats();           // Nuevo: estad√≠sticas detalladas
tree.print_stats();         // Nuevo: debug
```

#### 1.2 Crear alias para migraci√≥n gradual

Agregar a `include/ParallelAVL.hpp` (nuevo archivo):

```cpp
#ifndef PARALLEL_AVL_HPP
#define PARALLEL_AVL_HPP

// Opci√≥n de compilaci√≥n para elegir implementaci√≥n
#ifdef USE_DYNAMIC_SHARDS
    #include "DynamicShardedTree.hpp"
    template<typename K, typename V = K>
    using ParallelAVL = DynamicShardedTree<K, V>;
#else
    #include "AVLTreeParallel.h"
    template<typename K, typename V = K>
    using ParallelAVL = AVLTreeParallel<K, V>;
#endif

#endif
```

### Fase 2: Migraci√≥n de Tests (D√≠a 2)

#### 2.1 Actualizar tests existentes

```cpp
// Antes
#include "AVLTreeParallel.h"
AVLTreeParallel<int, int> tree(8);

// Despu√©s
#include "ParallelAVL.hpp"
ParallelAVL<int, int> tree;  // Usa config por defecto
```

#### 2.2 Crear test de regresi√≥n

```cpp
// tests/regression_dynamic_shards.cpp
void test_api_compatibility() {
    DynamicShardedTree<int, int> tree;
    
    // Todas las operaciones b√°sicas deben funcionar
    for (int i = 0; i < 10000; ++i) {
        tree.insert(i, i * 10);
    }
    
    assert(tree.size() == 10000);
    assert(tree.contains(5000));
    assert(tree.get(5000) == 50000);
    
    tree.remove(5000);
    assert(!tree.contains(5000));
    assert(tree.size() == 9999);
}

void test_scaling() {
    DynamicShardedTree<int, int> tree;
    
    // Insertar datos
    for (int i = 0; i < 50000; ++i) {
        tree.insert(i, i);
    }
    
    auto stats1 = tree.get_stats();
    assert(stats1.balance_score > 0.8);
    
    // Escalar
    tree.add_shard();
    tree.add_shard();
    tree.force_rebalance();
    
    auto stats2 = tree.get_stats();
    assert(stats2.balance_score > 0.8);
    assert(stats2.num_shards == stats1.num_shards + 2);
}
```

### Fase 3: Integraci√≥n en Benchmarks (D√≠a 3)

#### 3.1 Actualizar benchmark principal

```cpp
// benchmark_parallel_trees.cpp
#include "ParallelAVL.hpp"

// Compilar con:
// g++ -DUSE_DYNAMIC_SHARDS ... (usa DynamicShardedTree)
// g++ ...                      (usa AVLTreeParallel original)
```

#### 3.2 Agregar benchmark de scaling

```cpp
void benchmark_elastic_scaling() {
    DynamicShardedTree<int, int> tree;
    
    // Simular carga creciente
    for (int phase = 0; phase < 5; ++phase) {
        // Insertar datos
        insert_batch(tree, 100000);
        
        // Escalar si balance baja
        auto stats = tree.get_stats();
        if (stats.balance_score < 0.7) {
            tree.add_shard();
            tree.force_rebalance();
        }
        
        print_phase_stats(phase, stats);
    }
}
```

### Fase 4: Documentaci√≥n (D√≠a 4)

#### 4.1 Actualizar README.md

```markdown
## Uso B√°sico

### √Årbol Paralelo Est√°tico
```cpp
#include "AVLTreeParallel.h"
AVLTreeParallel<int, int> tree(8);  // 8 shards fijos
```

### √Årbol Paralelo Din√°mico (Recomendado)
```cpp
#include "DynamicShardedTree.hpp"

DynamicShardedTree<int, int>::Config config;
config.initial_shards = 4;
config.vnodes_per_shard = 64;

DynamicShardedTree<int, int> tree(config);

// Escalar cuando sea necesario
tree.add_shard();
tree.force_rebalance();
```
```

#### 4.2 Agregar ejemplos

```cpp
// examples/dynamic_scaling_example.cpp
#include "DynamicShardedTree.hpp"
#include <iostream>

int main() {
    DynamicShardedTree<std::string, int> cache;
    
    // Uso como cache
    cache.insert("user:1001", 42);
    cache.insert("user:1002", 37);
    
    // Escalar bajo demanda
    if (cache.size() > 100000) {
        cache.add_shard();
        cache.force_rebalance();
    }
    
    cache.print_stats();
    return 0;
}
```

### Fase 5: Deprecaci√≥n Gradual (Semana 2+)

#### 5.1 Marcar AVLTreeParallel como legacy

```cpp
// AVLTreeParallel.h
#ifndef AVL_TREE_PARALLEL_H
#define AVL_TREE_PARALLEL_H

#warning "AVLTreeParallel is deprecated. Use DynamicShardedTree instead."

// ... c√≥digo existente ...
```

#### 5.2 Timeline de deprecaci√≥n

| Fecha | Acci√≥n |
|-------|--------|
| Semana 1 | Integrar DynamicShardedTree, tests pasan |
| Semana 2 | Agregar warning de deprecaci√≥n |
| Semana 4 | Documentaci√≥n completa migrada |
| Semana 8 | Remover AVLTreeParallel del c√≥digo principal |

### Checklist de Integraci√≥n

- [ ] Crear `include/ParallelAVL.hpp` con alias
- [ ] Actualizar tests para usar nueva API
- [ ] Crear test de regresi√≥n espec√≠fico
- [ ] Actualizar benchmarks principales
- [ ] Actualizar README.md con ejemplos
- [ ] Agregar ejemplo de scaling din√°mico
- [ ] Marcar AVLTreeParallel como deprecated
- [ ] Actualizar documentaci√≥n del paper

---

## Pr√≥ximos Pasos Recomendados

### Corto Plazo (1-2 semanas)

1. **Integrar DynamicShardedTree** como opci√≥n principal
   - Documentar API en README
   - Agregar ejemplos de uso
   - Tests de regresi√≥n

2. **Limpiar c√≥digo experimental**
   - Remover AVLTreeParallelV2 (shared_mutex no aporta valor)
   - Remover PredictiveRouter (redundante)
   - Mantener solo DynamicShardedTree y router.hpp

3. **Benchmarks adicionales**
   - Probar con m√°s shards (16, 32, 64)
   - Medir latencia p99 durante scaling
   - Comparar con otras estructuras (ConcurrentHashMap, etc.)

### Mediano Plazo (1-3 meses)

4. **Optimizaciones del DynamicShardedTree**
   - Migraci√≥n background opcional (sin deadlocks)
   - Bulk rebalance para operaciones batch
   - M√©tricas de migraci√≥n (keys movidas, tiempo, etc.)

5. **Documentaci√≥n acad√©mica**
   - Paper sobre consistent hashing aplicado a √°rboles
   - Comparaci√≥n con Redis Cluster, DynamoDB

### Largo Plazo (si hay demanda)

6. **Extensi√≥n distribuida completa**
   - Solo si hay caso de uso real que lo justifique
   - Considerar usar librer√≠as existentes (gRPC, etcd) en lugar de reimplementar

---

## Archivos Creados

| Archivo | Descripci√≥n | Estado |
|---------|-------------|--------|
| `include/DynamicShardedTree.hpp` | Implementaci√≥n robusta de shards din√°micos | ‚úÖ Listo |
| `include/AVLTreeParallelV2.h` | Versi√≥n con shared_mutex | ‚ùå No recomendado |
| `include/PredictiveRouter.hpp` | Router ML-lite | ‚ö†Ô∏è Redundante |
| `include/DistributedAVL.hpp` | Framework distribuido | üìã Stub |
| `bench/dynamic_shards_bench.cpp` | Benchmark de shards din√°micos | ‚úÖ Listo |
| `bench/future_features_bench.cpp` | Benchmark de features V2 | ‚úÖ Listo |
| `tests/distributed_test.cpp` | Tests del cluster | ‚úÖ Listo |

---

## Conclusi√≥n

De las cuatro l√≠neas de trabajo futuro evaluadas, **solo los Shards Din√°micos demostraron valor real**:

- **shared_mutex**: Contraproducente para operaciones r√°pidas
- **Routing predictivo**: Redundante con hash robusto existente
- **Shards din√°micos**: **+43% throughput, balance mantenido** ‚úÖ
- **Distribuido**: Complejidad no justificada sin caso de uso

La recomendaci√≥n es **enfocarse en DynamicShardedTree** como la mejora principal del sistema, y posponer las dem√°s l√≠neas hasta que haya evidencia de necesidad real.

---

## Comandos √ötiles

```bash
# Compilar todo
make future

# Ejecutar benchmark de shards din√°micos
./bench_dynamic_shards

# Ejecutar todos los benchmarks V2
make run-future
```

---

*Documento generado como parte del an√°lisis de trabajos futuros del proyecto Parallel AVL Tree.*
